Quickstart
=======================================

Preparing the Environment
--------------------------

The first step is to clone the repository from Github:

::

    git clone https://github.com/lasseufpa/ptp-dal

Next, you need to install the Python dependencies. If using
*virtualenvwrapper*, run the following to create a virtual environment:

::

    mkvirtualenv -r requirements.txt ptp


Note the project requires Python 3.6 or higher.

Analysis
--------

The main script for synchronization analysis is ``analyze.py``, which
can be executed as follows:

::

    ./analyze.py -vvvv -f [dataset-filename]

The script will download the specified dataset automatically and process
it. Upon completion, the results become available in the ``results/``
directory.

Read the :ref:`dataset access` section for more information on how to access
pre-existing datasets.

Analysis Recipes
----------------

Directory ``recipes`` contains preset recipes for running a batch of
analyses based on distinct datasets. Refer to the instructions `in the
referred directory <recipes/README.md>`__.

Dataset Cataloging
------------------

Every dataset downloaded through ``analyze.py`` gets cataloged
automatically. The cataloging produces a JSON file at
``data/catalog.json`` and an HTML version at ``data/index.html``.

The dataset catalog can also be generated manually by calling:

::

    ./catalog.py

Simulator
---------

PTP-DAL also offers a simulator to generate a timestamp dataset
formatted similarly to the datasets acquired from the testbed. With
that, the same algorithms that can process timestamps from testbed
datasets can process the data from simulated datasets.

To generate a simulation dataset, define the target number of PTP
exchanges, and run with argument ``--save``. For example, for 10000
exchanges, run:

::

    ./simulate.py -vvvv -N 10000 --save

where argument ``-vvvv`` sets verbosity level 4 (info). Feel free to
adjust the verbosity level as needed. For example, level 5 (``-vvvvv``)
prints a great amount of debugging information.

After the simulation, the resulting (simulated) dataset is placed in the
``data/`` directory, where the analysis script expects it.

    NOTE: all datasets generated by simulation are prefixed ``sim-``. In
    contrast, datasets acquired serially from the testbed are prefixed
    with ``serial-``.